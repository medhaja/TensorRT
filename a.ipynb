{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorrt_llm import LLM, SamplingParams\n",
    "\n",
    "\n",
    "prompts = [\n",
    "\n",
    "    \"Hello, my name is\",\n",
    "\n",
    "    \"The president of the United States is\",\n",
    "\n",
    "    \"The capital of France is\",\n",
    "\n",
    "    \"The future of AI is\",\n",
    "\n",
    "]\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
    "\n",
    "\n",
    "llm = LLM(model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "\n",
    "# Print the outputs.\n",
    "\n",
    "for output in outputs:\n",
    "\n",
    "    prompt = output.prompt\n",
    "\n",
    "    generated_text = output.outputs[0].text\n",
    "\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import tensorrt_llm; print(tensorrt_llm._utils.trt_version())\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import sys; print(sys.executable)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir --extra-index-url https://pypi.nvidia.com tensorrt_bindings==9.2.0.post12.dev5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "trt.__version__\n",
    "# '9.3.0.post12.dev1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Users\\medha\\OneDrive\\Desktop\\WorkSpace\\tensorrt_llm\\TensorRT-LLM-main\\TensorRT-LLM-main\\tensorrt_llm\\__init__.py\", line 32, in <module>\n",
      "    import tensorrt_llm.functional as functional\n",
      "  File \"c:\\Users\\medha\\OneDrive\\Desktop\\WorkSpace\\tensorrt_llm\\TensorRT-LLM-main\\TensorRT-LLM-main\\tensorrt_llm\\functional.py\", line 28, in <module>\n",
      "    from . import graph_rewriting as gw\n",
      "  File \"c:\\Users\\medha\\OneDrive\\Desktop\\WorkSpace\\tensorrt_llm\\TensorRT-LLM-main\\TensorRT-LLM-main\\tensorrt_llm\\graph_rewriting.py\", line 12, in <module>\n",
      "    from .network import Network\n",
      "  File \"c:\\Users\\medha\\OneDrive\\Desktop\\WorkSpace\\tensorrt_llm\\TensorRT-LLM-main\\TensorRT-LLM-main\\tensorrt_llm\\network.py\", line 27, in <module>\n",
      "    from tensorrt_llm.module import Module\n",
      "  File \"c:\\Users\\medha\\OneDrive\\Desktop\\WorkSpace\\tensorrt_llm\\TensorRT-LLM-main\\TensorRT-LLM-main\\tensorrt_llm\\module.py\", line 17, in <module>\n",
      "    from ._common import default_net\n",
      "  File \"c:\\Users\\medha\\OneDrive\\Desktop\\WorkSpace\\tensorrt_llm\\TensorRT-LLM-main\\TensorRT-LLM-main\\tensorrt_llm\\_common.py\", line 37, in <module>\n",
      "    from ._utils import str_dtype_to_trt\n",
      "  File \"c:\\Users\\medha\\OneDrive\\Desktop\\WorkSpace\\tensorrt_llm\\TensorRT-LLM-main\\TensorRT-LLM-main\\tensorrt_llm\\_utils.py\", line 31, in <module>\n",
      "    from tensorrt_llm.bindings import GptJsonConfig\n",
      "ModuleNotFoundError: No module named 'tensorrt_llm.bindings'\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tensorrt_llm; print(tensorrt_llm._utils.trt_version())\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.3.0.post12.dev1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "trt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\medha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Create a dummy input\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(model, dummy_input, \"resnet50.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medha\\AppData\\Local\\Temp\\ipykernel_8708\\1146234682.py:18: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = 1 << 30  # 1 GB\n",
      "C:\\Users\\medha\\AppData\\Local\\Temp\\ipykernel_8708\\1146234682.py:27: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "# Load the ONNX model\n",
    "with open(\"resnet50.onnx\", \"rb\") as model:\n",
    "    onnx_model = model.read()\n",
    "\n",
    "# Create a TensorRT logger\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# Create a TensorRT builder and network\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "\n",
    "# Create a builder config\n",
    "config = builder.create_builder_config()\n",
    "config.max_workspace_size = 1 << 30  # 1 GB\n",
    "\n",
    "# Parse the ONNX model\n",
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "if not parser.parse(onnx_model):\n",
    "    for error in range(parser.num_errors):\n",
    "        print(parser.get_error(error))\n",
    "\n",
    "# Build the TensorRT engine\n",
    "engine = builder.build_engine(network, config)\n",
    "\n",
    "# Save the engine to a file\n",
    "with open(\"resnet50.trt\", \"wb\") as f:\n",
    "    f.write(engine.serialize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medha\\AppData\\Local\\Temp\\ipykernel_8708\\1212506721.py:34: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = 1 << 30  # 1 GB\n",
      "C:\\Users\\medha\\AppData\\Local\\Temp\\ipykernel_8708\\1212506721.py:43: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Inference Time: 0.1498 seconds\n",
      "TensorRT Inference Time: 0.0010 seconds\n",
      "Output comparison (first 10 values):\n",
      "PyTorch: tensor([-0.5746, -0.0726, -0.1359, -0.7958,  0.3136, -1.3083, -0.1524, -0.6186,\n",
      "         0.2323, -1.4385])\n",
      "TensorRT: [-0.57496476 -0.07318939 -0.1347372  -0.794315    0.31442487 -1.3087459\n",
      " -0.1512366  -0.61902785  0.23159608 -1.4398581 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load a pre-trained ResNet model from PyTorch\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Create a dummy input\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(model, dummy_input, \"resnet50.onnx\")\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"resnet50.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Create a TensorRT logger\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# Create a TensorRT builder and network\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "\n",
    "# Create a builder config\n",
    "config = builder.create_builder_config()\n",
    "config.max_workspace_size = 1 << 30  # 1 GB\n",
    "\n",
    "# Parse the ONNX model\n",
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "if not parser.parse(onnx_model.SerializeToString()):\n",
    "    for error in range(parser.num_errors):\n",
    "        print(parser.get_error(error))\n",
    "\n",
    "# Build the TensorRT engine\n",
    "engine = builder.build_engine(network, config)\n",
    "\n",
    "# Save the engine to a file\n",
    "with open(\"resnet50.trt\", \"wb\") as f:\n",
    "    f.write(engine.serialize())\n",
    "\n",
    "# Function to run inference with PyTorch model\n",
    "def run_pytorch_inference(model, input_data):\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data)\n",
    "    end_time = time.time()\n",
    "    return output, end_time - start_time\n",
    "\n",
    "# Function to run inference with TensorRT engine\n",
    "def run_tensorrt_inference(engine, input_data):\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    input_shape = (1, 3, 224, 224)\n",
    "    output_shape = (1, 1000)\n",
    "    d_input = cuda.mem_alloc(trt.volume(input_shape) * np.dtype(np.float32).itemsize)\n",
    "    d_output = cuda.mem_alloc(trt.volume(output_shape) * np.dtype(np.float32).itemsize)\n",
    "\n",
    "    stream = cuda.Stream()\n",
    "\n",
    "    cuda.memcpy_htod_async(d_input, input_data.numpy(), stream)\n",
    "\n",
    "    start_time = time.time()\n",
    "    context.execute_async_v2(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
    "    stream.synchronize()\n",
    "    end_time = time.time()\n",
    "\n",
    "    output_data = np.empty(output_shape, dtype=np.float32)\n",
    "    cuda.memcpy_dtoh_async(output_data, d_output, stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output_data, end_time - start_time\n",
    "\n",
    "# Run inference with PyTorch model\n",
    "pytorch_output, pytorch_time = run_pytorch_inference(model, dummy_input)\n",
    "\n",
    "# Load the TensorRT engine\n",
    "with open(\"resnet50.trt\", \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "# Run inference with TensorRT engine\n",
    "tensorrt_output, tensorrt_time = run_tensorrt_inference(engine, dummy_input)\n",
    "\n",
    "# Print the results\n",
    "print(f\"PyTorch Inference Time: {pytorch_time:.4f} seconds\")\n",
    "print(f\"TensorRT Inference Time: {tensorrt_time:.4f} seconds\")\n",
    "\n",
    "# Compare the outputs (optional)\n",
    "print(\"Output comparison (first 10 values):\")\n",
    "print(\"PyTorch:\", pytorch_output[0][:10])\n",
    "print(\"TensorRT:\", tensorrt_output[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mobilenet arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\medha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\medha\\AppData\\Local\\Temp\\ipykernel_15744\\234049197.py:33: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = 1 << 30  # 1 GB\n",
      "C:\\Users\\medha\\AppData\\Local\\Temp\\ipykernel_15744\\234049197.py:42: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Inference Time: 0.0238 seconds\n",
      "TensorRT Inference Time: 0.0000 seconds\n",
      "Output comparison (first 10 values):\n",
      "PyTorch: tensor([-1.8675,  0.5877,  1.1875,  0.9224,  1.8973,  3.7545,  2.6415, -0.4664,\n",
      "        -0.5275, -1.7199])\n",
      "TensorRT: [-1.8693478   0.5870544   1.1914711   0.9210633   1.9046966   3.754747\n",
      "  2.6366646  -0.46833465 -0.5303647  -1.7165513 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import onnx\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load a pre-trained MobileNetV2 model from PyTorch\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Create a dummy input\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(model, dummy_input, \"mobilenet_v2.onnx\")\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"mobilenet_v2.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Create a TensorRT logger\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# Create a TensorRT builder and network\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "\n",
    "# Create a builder config\n",
    "config = builder.create_builder_config()\n",
    "config.max_workspace_size = 1 << 30  # 1 GB\n",
    "\n",
    "# Parse the ONNX model\n",
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "if not parser.parse(onnx_model.SerializeToString()):\n",
    "    for error in range(parser.num_errors):\n",
    "        print(parser.get_error(error))\n",
    "\n",
    "# Build the TensorRT engine\n",
    "engine = builder.build_engine(network, config)\n",
    "\n",
    "# Save the engine to a file\n",
    "with open(\"mobilenet_v2.trt\", \"wb\") as f:\n",
    "    f.write(engine.serialize())\n",
    "\n",
    "# Function to run inference with PyTorch model\n",
    "def run_pytorch_inference(model, input_data):\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data)\n",
    "    end_time = time.time()\n",
    "    return output, end_time - start_time\n",
    "\n",
    "# Function to run inference with TensorRT engine\n",
    "def run_tensorrt_inference(engine, input_data):\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    input_shape = (1, 3, 224, 224)\n",
    "    output_shape = (1, 1000)\n",
    "    d_input = cuda.mem_alloc(trt.volume(input_shape) * np.dtype(np.float32).itemsize)\n",
    "    d_output = cuda.mem_alloc(trt.volume(output_shape) * np.dtype(np.float32).itemsize)\n",
    "\n",
    "    stream = cuda.Stream()\n",
    "\n",
    "    cuda.memcpy_htod_async(d_input, input_data.numpy(), stream)\n",
    "\n",
    "    start_time = time.time()\n",
    "    context.execute_async_v2(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
    "    stream.synchronize()\n",
    "    end_time = time.time()\n",
    "\n",
    "    output_data = np.empty(output_shape, dtype=np.float32)\n",
    "    cuda.memcpy_dtoh_async(output_data, d_output, stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output_data, end_time - start_time\n",
    "\n",
    "# Run inference with PyTorch model\n",
    "pytorch_output, pytorch_time = run_pytorch_inference(model, dummy_input)\n",
    "\n",
    "# Load the TensorRT engine\n",
    "with open(\"mobilenet_v2.trt\", \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "# Run inference with TensorRT engine\n",
    "tensorrt_output, tensorrt_time = run_tensorrt_inference(engine, dummy_input)\n",
    "\n",
    "# Print the results\n",
    "print(f\"PyTorch Inference Time: {pytorch_time:.4f} seconds\")\n",
    "print(f\"TensorRT Inference Time: {tensorrt_time:.4f} seconds\")\n",
    "\n",
    "# Compare the outputs (optional)\n",
    "print(\"Output comparison (first 10 values):\")\n",
    "print(\"PyTorch:\", pytorch_output[0][:10])\n",
    "print(\"TensorRT:\", tensorrt_output[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medha\\AppData\\Local\\Temp\\ipykernel_22660\\335943676.py:33: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = 1 << 30  # 1 GB\n",
      "C:\\Users\\medha\\AppData\\Local\\Temp\\ipykernel_22660\\335943676.py:42: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Mean Inference Time: 0.0193 seconds\n",
      "TensorRT Mean Inference Time: 0.0011 seconds\n",
      "Output comparison (first 10 values):\n",
      "PyTorch: tensor([-1.8003,  0.8952,  1.5019,  1.0823,  2.4900,  4.0107,  2.8733, -0.6329,\n",
      "        -0.8625, -1.3930])\n",
      "TensorRT: [-1.8063918  0.8972742  1.5052394  1.0819196  2.4986641  4.008527\n",
      "  2.8675916 -0.6365201 -0.867194  -1.388763 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import onnx\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load a pre-trained MobileNetV2 model from PyTorch\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Create a dummy input\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(model, dummy_input, \"mobilenet_v2.onnx\")\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"mobilenet_v2.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Create a TensorRT logger\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# Create a TensorRT builder and network\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "\n",
    "# Create a builder config\n",
    "config = builder.create_builder_config()\n",
    "config.max_workspace_size = 1 << 30  # 1 GB\n",
    "\n",
    "# Parse the ONNX model\n",
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "if not parser.parse(onnx_model.SerializeToString()):\n",
    "    for error in range(parser.num_errors):\n",
    "        print(parser.get_error(error))\n",
    "\n",
    "# Build the TensorRT engine\n",
    "engine = builder.build_engine(network, config)\n",
    "\n",
    "# Save the engine to a file\n",
    "with open(\"mobilenet_v2.trt\", \"wb\") as f:\n",
    "    f.write(engine.serialize())\n",
    "\n",
    "# Function to run inference with PyTorch model\n",
    "def run_pytorch_inference(model, input_data):\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data)\n",
    "    end_time = time.time()\n",
    "    return output, end_time - start_time\n",
    "\n",
    "# Function to run inference with TensorRT engine\n",
    "def run_tensorrt_inference(engine, input_data):\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    input_shape = (1, 3, 224, 224)\n",
    "    output_shape = (1, 1000)\n",
    "    d_input = cuda.mem_alloc(trt.volume(input_shape) * np.dtype(np.float32).itemsize)\n",
    "    d_output = cuda.mem_alloc(trt.volume(output_shape) * np.dtype(np.float32).itemsize)\n",
    "\n",
    "    stream = cuda.Stream()\n",
    "\n",
    "    cuda.memcpy_htod_async(d_input, input_data.numpy(), stream)\n",
    "\n",
    "    start_time = time.time()\n",
    "    context.execute_async_v2(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
    "    stream.synchronize()\n",
    "    end_time = time.time()\n",
    "\n",
    "    output_data = np.empty(output_shape, dtype=np.float32)\n",
    "    cuda.memcpy_dtoh_async(output_data, d_output, stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output_data, end_time - start_time\n",
    "\n",
    "# Run inference for 10 images with PyTorch model\n",
    "pytorch_times = []\n",
    "for _ in range(10):\n",
    "    pytorch_output, pytorch_time = run_pytorch_inference(model, dummy_input)\n",
    "    pytorch_times.append(pytorch_time)\n",
    "\n",
    "# Load the TensorRT engine\n",
    "with open(\"mobilenet_v2.trt\", \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "# Run inference for 10 images with TensorRT engine\n",
    "tensorrt_times = []\n",
    "for _ in range(10000):\n",
    "    tensorrt_output, tensorrt_time = run_tensorrt_inference(engine, dummy_input)\n",
    "    tensorrt_times.append(tensorrt_time)\n",
    "\n",
    "# Calculate the mean inference times\n",
    "pytorch_mean_time = np.mean(pytorch_times)\n",
    "tensorrt_mean_time = np.mean(tensorrt_times)\n",
    "\n",
    "# Print the results\n",
    "print(f\"PyTorch Mean Inference Time: {pytorch_mean_time:.4f} seconds\")\n",
    "print(f\"TensorRT Mean Inference Time: {tensorrt_mean_time:.4f} seconds\")\n",
    "\n",
    "# Compare the outputs (optional)\n",
    "print(\"Output comparison (first 10 values):\")\n",
    "print(\"PyTorch:\", pytorch_output[0][:10])\n",
    "print(\"TensorRT:\", tensorrt_output[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medha\\AppData\\Local\\Temp\\ipykernel_22660\\4245462046.py:59: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = 1 << 30  # 1 GB\n",
      "C:\\Users\\medha\\AppData\\Local\\Temp\\ipykernel_22660\\4245462046.py:68: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Mean Inference Time: 0.0181 seconds\n",
      "TensorRT Mean Inference Time: 0.0010 seconds\n",
      "Output comparison (first 10 values):\n",
      "PyTorch: tensor([-3.5619, -4.0951, -3.6673, -2.8357, -4.7341,  2.1568, -2.5343,  4.4799,\n",
      "         6.1202,  4.7775])\n",
      "TensorRT: [-3.563822  -4.0938277 -3.6695344 -2.8367448 -4.7342696  2.1580381\n",
      " -2.529145   4.472117   6.1067324  4.7731795]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import onnx\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load a pre-trained MobileNetV2 model from PyTorch\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "# Load images from the specified folder\n",
    "image_folder = \"C:\\\\Users\\\\medha\\\\OneDrive\\\\Desktop\\\\WorkSpace\\\\tensorrt_llm\\\\TensorRT-LLM-main\\\\TensorRT-LLM-main\\\\data\"\n",
    "images = load_images_from_folder(image_folder)\n",
    "\n",
    "# Create a dummy input for ONNX export\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(model, dummy_input, \"mobilenet_v2.onnx\")\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"mobilenet_v2.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Create a TensorRT logger\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# Create a TensorRT builder and network\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "\n",
    "# Create a builder config\n",
    "config = builder.create_builder_config()\n",
    "config.max_workspace_size = 1 << 30  # 1 GB\n",
    "\n",
    "# Parse the ONNX model\n",
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "if not parser.parse(onnx_model.SerializeToString()):\n",
    "    for error in range(parser.num_errors):\n",
    "        print(parser.get_error(error))\n",
    "\n",
    "# Build the TensorRT engine\n",
    "engine = builder.build_engine(network, config)\n",
    "\n",
    "# Save the engine to a file\n",
    "with open(\"mobilenet_v2.trt\", \"wb\") as f:\n",
    "    f.write(engine.serialize())\n",
    "\n",
    "# Function to run inference with PyTorch model\n",
    "def run_pytorch_inference(model, input_data):\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data)\n",
    "    end_time = time.time()\n",
    "    return output, end_time - start_time\n",
    "\n",
    "# Function to run inference with TensorRT engine\n",
    "def run_tensorrt_inference(engine, input_data):\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    input_shape = (1, 3, 224, 224)\n",
    "    output_shape = (1, 1000)\n",
    "    d_input = cuda.mem_alloc(trt.volume(input_shape) * np.dtype(np.float32).itemsize)\n",
    "    d_output = cuda.mem_alloc(trt.volume(output_shape) * np.dtype(np.float32).itemsize)\n",
    "\n",
    "    stream = cuda.Stream()\n",
    "\n",
    "    cuda.memcpy_htod_async(d_input, input_data.numpy(), stream)\n",
    "\n",
    "    start_time = time.time()\n",
    "    context.execute_async_v2(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
    "    stream.synchronize()\n",
    "    end_time = time.time()\n",
    "\n",
    "    output_data = np.empty(output_shape, dtype=np.float32)\n",
    "    cuda.memcpy_dtoh_async(output_data, d_output, stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output_data, end_time - start_time\n",
    "\n",
    "# Run inference for all images with PyTorch model\n",
    "pytorch_times = []\n",
    "for image in images:\n",
    "    pytorch_output, pytorch_time = run_pytorch_inference(model, image)\n",
    "    pytorch_times.append(pytorch_time)\n",
    "\n",
    "# Load the TensorRT engine\n",
    "with open(\"mobilenet_v2.trt\", \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "# Run inference for all images with TensorRT engine\n",
    "tensorrt_times = []\n",
    "for image in images:\n",
    "    tensorrt_output, tensorrt_time = run_tensorrt_inference(engine, image)\n",
    "    tensorrt_times.append(tensorrt_time)\n",
    "\n",
    "# Calculate the mean inference times\n",
    "pytorch_mean_time = np.mean(pytorch_times)\n",
    "tensorrt_mean_time = np.mean(tensorrt_times)\n",
    "\n",
    "# Print the results\n",
    "print(f\"PyTorch Mean Inference Time: {pytorch_mean_time:.4f} seconds\")\n",
    "print(f\"TensorRT Mean Inference Time: {tensorrt_mean_time:.4f} seconds\")\n",
    "\n",
    "# Compare the outputs (optional)\n",
    "print(\"Output comparison (first 10 values):\")\n",
    "print(\"PyTorch:\", pytorch_output[0][:10])\n",
    "print(\"TensorRT:\", tensorrt_output[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.56468844e+00, -4.09343672e+00, -3.67025805e+00,\n",
       "        -2.83583307e+00, -4.73365116e+00,  2.15937638e+00,\n",
       "        -2.52551246e+00,  4.47502899e+00,  6.11003780e+00,\n",
       "         4.77815390e+00,  3.13727617e+00,  5.90626001e+00,\n",
       "        -3.33273560e-01,  3.58156228e+00,  2.00163436e+00,\n",
       "         6.17331123e+00,  4.71036911e+00,  5.22766781e+00,\n",
       "         1.64498940e+01,  1.55936766e+00,  8.93960476e+00,\n",
       "         9.11338329e+00,  5.82359076e+00,  9.26880360e+00,\n",
       "         3.86119056e+00,  3.98992300e+00,  2.55849862e+00,\n",
       "        -3.25195253e-01,  1.13354301e+00,  1.71742201e+00,\n",
       "        -3.13251436e-01, -2.18315482e+00, -9.31978941e-01,\n",
       "        -5.53848791e+00, -2.55483007e+00, -2.85994315e+00,\n",
       "        -2.33441067e+00, -2.93612838e+00,  2.56323874e-01,\n",
       "        -1.82660627e+00, -1.44587386e+00,  8.03206503e-01,\n",
       "        -2.17043400e+00, -2.22206259e+00, -1.19699550e+00,\n",
       "        -6.93717718e-01, -2.35134435e+00, -2.15511298e+00,\n",
       "         3.14973742e-01, -7.32031882e-01, -1.48200405e+00,\n",
       "        -2.50299406e+00, -3.25730562e-01,  8.18069652e-02,\n",
       "         1.73479006e-01, -4.23719645e+00, -6.12577140e-01,\n",
       "        -1.63175941e+00, -1.83463705e+00,  1.22557056e+00,\n",
       "         9.66373086e-01, -1.94029391e+00,  8.90060663e-01,\n",
       "         1.34866011e+00, -1.84561920e+00,  2.87788481e-01,\n",
       "         1.63092422e+00,  6.55824840e-01,  1.31362987e+00,\n",
       "        -1.22951806e+00, -3.69499588e+00,  2.24775262e-03,\n",
       "        -5.00399411e-01, -1.61350536e+00, -1.26282692e+00,\n",
       "        -1.70584714e+00, -2.44884515e+00, -1.19032264e+00,\n",
       "        -1.20867825e+00,  8.82095098e-01,  1.52577877e+01,\n",
       "         7.56166077e+00,  6.59443188e+00,  1.06340914e+01,\n",
       "         5.76310158e+00,  7.59600592e+00,  8.51445293e+00,\n",
       "         2.15531301e+00,  2.54225564e+00,  9.40654993e-01,\n",
       "        -2.29557276e+00,  8.09539604e+00,  9.26888108e-01,\n",
       "         8.76771832e+00, -1.43220866e+00,  5.51430702e-01,\n",
       "         6.15954161e+00,  2.93331146e+00,  1.98309493e+00,\n",
       "         5.72025633e+00,  2.65594935e+00,  1.36743200e+00,\n",
       "        -1.92044628e+00, -1.89524829e+00, -1.96341777e+00,\n",
       "        -5.50493526e+00, -1.67157978e-01, -5.32125235e+00,\n",
       "        -1.39541698e+00, -2.96075368e+00, -1.74857867e+00,\n",
       "        -9.52523530e-01, -2.02778459e+00, -4.75516558e+00,\n",
       "        -1.27640557e+00,  1.12182307e+00, -4.52532530e+00,\n",
       "        -2.69617766e-01, -8.40770960e-01, -2.25552738e-01,\n",
       "        -2.74555802e+00, -7.31082022e-01,  1.41033515e-01,\n",
       "        -2.06954575e+00,  3.50989759e-01, -1.17547905e+00,\n",
       "         8.76028717e-01,  4.43023157e+00,  5.28088331e+00,\n",
       "         9.74220634e-01, -2.46533275e-01,  3.21875525e+00,\n",
       "         2.55775118e+00,  5.75596380e+00,  6.31129408e+00,\n",
       "         1.32505202e+00,  6.39628172e+00,  6.79715919e+00,\n",
       "         6.81105328e+00,  3.99783707e+00,  2.29993391e+00,\n",
       "        -3.68432730e-01,  5.13705552e-01,  7.88024998e+00,\n",
       "        -1.05397868e+00,  7.56934500e+00,  6.35764360e+00,\n",
       "         8.70874166e-01,  8.16030681e-01, -4.04480791e+00,\n",
       "        -1.63534307e+00,  1.96776474e+00,  1.84979177e+00,\n",
       "        -4.15726483e-01, -1.69621682e+00, -3.13306141e+00,\n",
       "        -1.41866291e+00,  5.35615027e-01,  9.56688523e-01,\n",
       "         1.06910741e+00,  1.24822676e+00, -1.02761137e+00,\n",
       "        -6.92373931e-01,  1.29373312e-01,  2.06131768e+00,\n",
       "        -4.71832246e-01,  9.31430817e-01,  7.88371682e-01,\n",
       "        -1.59604704e+00,  3.62903762e+00, -3.72018665e-01,\n",
       "         3.60650063e+00,  6.59702730e+00,  5.34825754e+00,\n",
       "         1.03445187e-01, -1.89087617e+00,  5.33311129e+00,\n",
       "         3.41152096e+00, -1.39367676e+00,  3.23002172e+00,\n",
       "         3.02839303e+00, -7.39641488e-01, -7.38809109e-02,\n",
       "         2.96024776e+00,  1.04268324e+00,  1.27690148e+00,\n",
       "         2.26136899e+00, -1.24725890e+00,  1.59085345e+00,\n",
       "         1.71807396e+00, -1.52873710e-01, -6.77265167e-01,\n",
       "        -6.64858341e-01,  1.06329942e+00, -3.50955820e+00,\n",
       "         3.39323640e+00,  8.61386180e-01,  8.97528112e-01,\n",
       "         2.02094769e+00,  7.45357931e-01,  5.73010206e-01,\n",
       "        -2.47038174e+00, -3.71380188e-02,  6.38648331e-01,\n",
       "        -1.73469293e+00, -8.33039209e-02,  1.60421038e+00,\n",
       "        -2.98816371e+00, -1.08088028e+00, -2.78504443e+00,\n",
       "         2.80587703e-01,  4.53004777e-01, -1.29883039e+00,\n",
       "        -1.78688920e+00, -1.19771981e+00,  2.76921242e-01,\n",
       "        -2.40224075e+00, -5.78700423e-01, -3.01881552e+00,\n",
       "        -1.12470007e+00, -5.17754495e-01, -2.43963742e+00,\n",
       "         1.35641122e+00, -2.29656786e-01,  5.60265303e-01,\n",
       "        -3.74190748e-01, -8.34767461e-01,  2.62900662e+00,\n",
       "        -1.95286775e+00, -1.66251078e-01, -9.69085693e-02,\n",
       "         3.55690837e+00,  5.30663061e+00,  2.63512433e-01,\n",
       "        -5.58409691e-01,  9.00865376e-01,  1.10861480e+00,\n",
       "         1.97732002e-02,  3.07217479e+00,  2.52996445e-01,\n",
       "         4.96178722e+00,  4.05287027e+00,  6.64880693e-01,\n",
       "         6.64357543e-01, -3.65001512e+00, -2.38636088e+00,\n",
       "         1.71388376e+00, -4.54683018e+00,  1.22407389e+00,\n",
       "         4.96253297e-02,  5.91676831e-01, -3.92763764e-01,\n",
       "        -1.42425966e+00,  4.15521288e+00, -1.65691614e+00,\n",
       "        -2.18855786e+00, -1.30180490e+00, -1.04493833e+00,\n",
       "        -1.36589304e-01,  1.86686128e-01, -4.18048000e+00,\n",
       "        -9.84579250e-02, -5.12372553e-01,  2.18297020e-01,\n",
       "         2.90696478e+00, -1.21699679e+00, -9.42854762e-01,\n",
       "         1.53524435e+00,  1.79596722e-01,  1.30325723e+00,\n",
       "         5.25361776e-01,  6.12409592e-01,  1.52969575e+00,\n",
       "         1.48419774e+00,  2.03782749e+00,  5.04539776e+00,\n",
       "         8.97989571e-01, -8.25326622e-01, -8.93999040e-01,\n",
       "        -7.19725847e-01,  1.09493303e+00, -7.67270684e-01,\n",
       "         3.99974346e-01,  5.39724290e-01, -3.75447607e+00,\n",
       "         4.27086204e-02, -2.82629442e+00,  5.28616071e-01,\n",
       "         3.04382503e-01, -2.47603106e+00,  1.62161469e-01,\n",
       "         3.88055474e-01, -1.50237143e+00,  9.17397916e-01,\n",
       "        -2.42881250e+00,  4.90774751e-01, -4.69869184e+00,\n",
       "         2.31996679e+00,  1.41460681e+00, -9.36009347e-01,\n",
       "         1.16181755e+00,  1.98801768e+00,  2.74079418e+00,\n",
       "         1.61393449e-01, -3.48361492e-01,  2.66879725e+00,\n",
       "         1.11033630e+00,  2.44360161e+00, -4.81876016e-01,\n",
       "        -1.16382182e+00,  1.92104650e+00, -9.75963116e-01,\n",
       "         1.00681126e+00, -2.98544717e+00,  2.15358421e-01,\n",
       "        -2.08925653e+00, -2.98881650e+00,  7.33622134e-01,\n",
       "        -1.51738095e+00, -2.32423162e+00, -2.91609144e+00,\n",
       "        -8.47351670e-01, -2.25620580e+00, -2.44387984e+00,\n",
       "        -3.03207707e+00, -4.63086271e+00, -1.94435489e+00,\n",
       "        -2.04241848e+00, -4.66943502e+00, -9.46862876e-01,\n",
       "        -1.17799711e+00,  3.59842587e+00,  7.98103631e-01,\n",
       "        -1.11612082e+00, -3.36447549e+00, -9.21673894e-01,\n",
       "         7.92297125e-02, -2.04265380e+00,  2.60639238e+00,\n",
       "         2.05390787e+00,  3.28369665e+00,  1.55829763e+00,\n",
       "        -2.75627077e-01,  8.00115228e-01, -1.47703111e+00,\n",
       "         3.19588876e+00,  6.22355998e-01, -1.68200445e+00,\n",
       "         7.30583858e+00,  5.09182310e+00,  1.08871722e+00,\n",
       "         7.67533958e-01,  1.52233124e+00,  2.92143154e+00,\n",
       "         1.16403496e+00,  1.96121156e+00, -5.55601954e-01,\n",
       "        -7.89157927e-01,  9.43479061e-01, -7.00790584e-01,\n",
       "        -1.48369539e+00,  4.12208080e+00,  3.47619462e+00,\n",
       "         9.61394489e-01, -2.69084430e+00, -6.85037041e+00,\n",
       "        -4.13816023e+00, -2.40328026e+00, -2.42776799e+00,\n",
       "        -5.27223468e-01,  3.24958873e+00,  2.13630962e+00,\n",
       "         1.19610620e+00, -6.73427820e-01, -9.09815848e-01,\n",
       "         1.51816332e+00, -4.35217333e+00,  1.10711563e+00,\n",
       "        -2.31641078e+00, -5.25406122e+00, -7.93161571e-01,\n",
       "        -5.07824230e+00, -3.19061923e+00,  9.56857741e-01,\n",
       "         3.20878267e+00, -1.53578484e+00, -2.89435208e-01,\n",
       "        -1.49067783e+00, -2.22293139e+00, -2.60398239e-01,\n",
       "        -1.64122736e+00, -1.84728611e+00, -1.10139012e+00,\n",
       "        -1.37432814e+00,  2.11144567e-01, -1.46423697e+00,\n",
       "        -4.00449610e+00, -3.83637619e+00,  1.74974346e+00,\n",
       "         3.30904746e+00, -4.38913703e-01,  3.92930484e+00,\n",
       "         2.62210202e+00, -2.61042833e+00, -1.72953331e+00,\n",
       "        -6.43361807e-01, -4.02743292e+00, -7.34814823e-01,\n",
       "         1.31182265e+00, -8.51570010e-01, -4.48349571e+00,\n",
       "         1.84914485e-01,  1.55371380e+00, -9.73477304e-01,\n",
       "         9.88368511e-01, -1.19522142e+00, -2.27410293e+00,\n",
       "        -2.76313663e+00, -2.24761441e-02, -3.50518465e-01,\n",
       "        -2.69471496e-01,  2.10869026e+00,  1.12974867e-01,\n",
       "        -2.80950046e+00, -2.76880574e+00,  1.92643464e+00,\n",
       "         1.08803526e-01,  2.53400874e+00,  4.83709764e+00,\n",
       "         3.02893567e+00, -3.59784412e+00,  9.14404035e-01,\n",
       "        -1.85073638e+00, -1.63425756e+00, -5.73846065e-02,\n",
       "         2.48705411e+00, -8.83762777e-01,  1.33593893e+00,\n",
       "         2.47826800e-01,  3.35634917e-01,  2.33059913e-01,\n",
       "        -1.94890642e+00, -1.10194415e-01, -2.09019974e-01,\n",
       "         1.83341837e+00, -3.65558338e+00,  6.10301018e-01,\n",
       "         6.55606842e+00, -3.83610892e+00,  5.42935908e-01,\n",
       "        -2.66247797e+00,  1.47566155e-01, -7.14010775e-01,\n",
       "        -2.31787086e+00, -1.86263406e+00, -5.63162231e+00,\n",
       "         2.33416334e-01,  1.15488100e+00, -3.23693395e-01,\n",
       "        -4.59741026e-01,  1.41677523e+00,  1.42699087e+00,\n",
       "        -8.40386033e-01,  1.24286759e+00,  1.03524935e+00,\n",
       "         2.22119975e+00, -6.72246337e-01, -8.84414554e-01,\n",
       "         8.79067406e-02,  4.81219149e+00, -1.05716622e+00,\n",
       "        -6.65523633e-02,  1.55654502e+00, -1.05796838e+00,\n",
       "        -2.31090021e+00,  5.83811812e-02, -2.52951050e+00,\n",
       "         9.12813008e-01,  2.11986518e+00,  1.64372921e+00,\n",
       "        -2.91640210e+00, -1.32747424e+00,  9.26514924e-01,\n",
       "        -1.05934119e+00, -2.89431739e+00,  7.47164845e-01,\n",
       "        -3.20583463e+00,  2.60710669e+00,  4.57765388e+00,\n",
       "         1.81572187e+00, -1.05965161e+00, -2.09650183e+00,\n",
       "        -3.08685350e+00, -1.86713862e+00,  1.71383464e+00,\n",
       "        -3.05233645e+00, -5.76077127e+00, -2.93466640e+00,\n",
       "        -2.54043961e+00,  4.71632957e-01, -2.70099711e+00,\n",
       "         2.03155351e+00, -8.27186882e-01, -3.88381869e-01,\n",
       "         1.41087389e+00,  6.09535694e-01,  5.83922744e-01,\n",
       "         2.72636443e-01,  8.01497698e-01, -4.42352504e-01,\n",
       "        -3.62706399e+00, -5.93767613e-02,  1.48670748e-03,\n",
       "        -4.91727054e-01, -1.42887741e-01,  2.08674788e+00,\n",
       "         8.37459683e-01,  6.30901009e-02,  2.20562547e-01,\n",
       "         3.96458596e-01,  1.83237183e+00, -4.18784708e-01,\n",
       "         2.85500789e+00,  3.47059155e+00,  7.95265436e-01,\n",
       "        -3.16722870e-01, -2.83762741e+00, -3.12228107e+00,\n",
       "        -1.34691317e-02, -1.34485114e+00, -1.85812938e+00,\n",
       "        -9.04191732e-02, -2.39997745e+00, -3.39889002e+00,\n",
       "         7.21217632e-01,  3.04795224e-02, -1.31917477e+00,\n",
       "        -6.98458016e-01, -6.08597025e-02,  5.39540172e-01,\n",
       "        -3.52595448e+00,  3.04107594e+00, -9.71612215e-01,\n",
       "         1.87646449e+00,  1.40381980e+00,  7.86484778e-01,\n",
       "        -7.79658735e-01, -1.60902202e+00, -3.01370406e+00,\n",
       "        -2.20907903e+00,  3.52574348e-01, -5.47851741e-01,\n",
       "         1.24683321e+00, -3.28722215e+00, -4.68272734e+00,\n",
       "        -2.85438824e+00,  1.45885754e+00,  4.68544751e-01,\n",
       "        -7.95895159e-01,  2.15034676e+00, -2.95801711e+00,\n",
       "        -8.71900916e-01, -6.58592820e-01, -6.98116601e-01,\n",
       "        -2.61072636e+00,  5.75805604e-01, -1.27412987e+00,\n",
       "         1.71582270e+00, -2.40254021e+00, -2.49610603e-01,\n",
       "         1.85516447e-01, -2.57331759e-01, -8.54587495e-01,\n",
       "         1.75515056e+00,  2.16248584e+00,  1.01757514e+00,\n",
       "         2.75255156e+00,  1.85390723e+00, -2.35717744e-01,\n",
       "        -1.37639594e+00,  1.31244794e-01, -5.25276780e-01,\n",
       "        -2.37176865e-01, -2.26705480e+00, -4.22888815e-01,\n",
       "        -1.55837488e+00, -3.04634303e-01,  1.95257521e+00,\n",
       "         1.24948132e+00, -9.80953753e-01, -1.07776856e+00,\n",
       "        -1.99120176e+00,  2.74433464e-01,  1.58649850e+00,\n",
       "        -1.01196289e+00,  3.32553172e+00,  6.53402865e-01,\n",
       "        -1.50633907e+00, -4.66198206e-01, -2.04796576e+00,\n",
       "         2.10325074e+00, -2.16891706e-01, -1.05513704e+00,\n",
       "         3.29636820e-02, -1.12806952e+00, -2.17345548e+00,\n",
       "         1.33387053e+00, -1.17341590e+00, -8.57884586e-01,\n",
       "         6.48064315e-01, -3.12208557e+00, -4.69894409e+00,\n",
       "         1.64975333e+00,  2.21932840e+00, -2.35636806e+00,\n",
       "        -2.05803394e-01,  7.43165612e-01, -1.84657097e+00,\n",
       "        -5.42600632e-01, -1.59942913e+00, -2.80454993e+00,\n",
       "         1.62237656e+00,  2.51827717e+00, -1.15542209e+00,\n",
       "        -1.56812894e+00, -1.45266151e+00,  2.47880864e+00,\n",
       "        -1.56131101e+00,  6.09990716e-01,  2.05197372e-02,\n",
       "        -5.31518340e-01,  1.36877406e+00,  5.26420951e-01,\n",
       "         2.57645845e+00, -6.74440265e-02, -2.03151917e+00,\n",
       "         1.58498096e+00, -2.42799377e+00, -3.55323285e-01,\n",
       "        -2.51592427e-01, -2.23047423e+00, -9.78718638e-01,\n",
       "        -1.67968988e+00, -1.91365552e+00,  1.24493635e+00,\n",
       "        -3.14610243e+00, -3.28038990e-01,  1.98742008e+00,\n",
       "         8.96612227e-01,  2.10363626e+00,  1.10319448e+00,\n",
       "        -3.11902070e+00,  1.84420419e+00,  3.78279901e+00,\n",
       "         1.85728800e+00, -2.72915196e+00, -1.35920495e-01,\n",
       "         1.92000031e-01, -2.40325212e+00, -7.65072584e-01,\n",
       "         1.90208340e+00,  6.34135425e-01,  1.57341790e+00,\n",
       "        -9.08137977e-01, -1.34746283e-01,  1.97985053e+00,\n",
       "        -1.42251626e-01,  3.20495605e-01, -3.85139871e+00,\n",
       "        -2.28230286e+00,  1.46269548e+00,  1.37534797e+00,\n",
       "         1.19862342e+00, -5.57798967e-02, -1.42448807e+00,\n",
       "        -8.66812170e-01,  2.48670840e+00,  1.51333332e+00,\n",
       "         1.44744492e+00, -3.60036254e+00,  8.56268108e-01,\n",
       "        -1.91262829e+00, -2.77217531e+00, -1.21550667e+00,\n",
       "        -2.89940524e+00, -8.15669894e-02,  8.46683562e-01,\n",
       "        -4.34322453e+00, -1.03367758e+00, -1.37325275e+00,\n",
       "         9.38008070e-01, -1.18361890e+00, -1.46900403e+00,\n",
       "         1.28121689e-01, -2.98581457e+00,  2.34368467e+00,\n",
       "        -3.33199668e+00, -1.95273662e+00,  8.58562052e-01,\n",
       "         5.75611115e-01,  1.09285271e+00,  1.10883105e+00,\n",
       "        -5.45827866e-01,  2.35458183e+00, -4.68084604e-01,\n",
       "         2.69267321e+00, -7.47507572e-01,  2.58707380e+00,\n",
       "         1.10352290e+00, -6.27369225e-01, -1.46154571e+00,\n",
       "        -1.92993891e+00, -2.60657644e+00, -3.77638817e-01,\n",
       "        -2.08203721e+00, -1.74350810e+00,  3.13228559e+00,\n",
       "        -6.23752594e-01, -2.63957024e-01, -2.60592580e+00,\n",
       "         2.85194069e-01, -1.40853071e+00,  2.61355305e+00,\n",
       "         2.26612836e-01, -3.73150015e+00,  2.55926991e+00,\n",
       "         9.55002725e-01, -2.10370108e-01, -4.04160708e-01,\n",
       "        -3.26605320e+00,  4.73875093e+00,  2.88795799e-01,\n",
       "         3.39068866e+00,  1.59058356e+00, -6.12233400e-01,\n",
       "        -1.74751949e+00,  3.67432982e-01, -8.23686004e-01,\n",
       "        -1.21726489e+00, -2.29243135e+00, -4.61775839e-01,\n",
       "        -2.14580464e+00, -1.00568366e+00, -1.38631725e+00,\n",
       "         1.91522360e+00,  1.48793712e-01,  3.93139672e+00,\n",
       "        -1.90738463e+00,  5.35377204e-01,  1.61876225e+00,\n",
       "         1.00900102e+00,  6.15752459e-01, -1.64806712e+00,\n",
       "         3.92084885e+00,  2.62455392e+00,  3.09331685e-01,\n",
       "         1.34386384e+00,  1.67166102e+00,  3.11463594e-01,\n",
       "         2.08216524e+00, -1.41823864e+00,  2.05657434e+00,\n",
       "        -2.60479897e-01, -2.42007661e+00, -5.22782147e-01,\n",
       "         7.29283035e-01, -2.74291229e+00,  2.06185892e-01,\n",
       "         1.99283946e+00,  7.70771384e-01, -1.15916230e-01,\n",
       "         1.84167838e+00,  1.29032159e+00,  1.29696071e+00,\n",
       "         2.10781622e+00, -1.03053033e+00, -1.40284717e+00,\n",
       "         1.96761727e-01, -1.16308376e-01,  2.21274567e+00,\n",
       "        -9.51540887e-01, -1.59659684e-01, -1.67630005e+00,\n",
       "         1.13153493e+00,  7.03122616e-01, -5.27543902e-01,\n",
       "        -1.65441227e+00,  2.87241507e+00, -1.90335083e+00,\n",
       "        -2.87397027e-01,  2.82216740e+00, -1.25526810e+00,\n",
       "        -1.40041578e+00, -1.36152887e+00,  5.29631317e-01,\n",
       "        -1.46605462e-01, -1.88429272e+00,  1.72651029e+00,\n",
       "        -2.21077144e-01,  1.63309276e-01, -2.09709454e+00,\n",
       "        -3.59619689e+00, -2.05035233e+00, -2.44846869e+00,\n",
       "         1.63951457e+00,  1.83619767e-01, -2.44484878e+00,\n",
       "         2.81955695e+00,  1.21920693e+00,  5.11745930e-01,\n",
       "         4.58554447e-01,  1.74213743e+00,  9.01398838e-01,\n",
       "        -4.15108442e-01,  1.92116857e+00, -3.52051198e-01,\n",
       "        -4.94869423e+00, -1.15056658e+00,  1.44869781e+00,\n",
       "        -1.43364453e+00,  1.47072423e+00, -4.82412517e-01,\n",
       "         4.41296399e-01,  7.00576454e-02,  4.66296643e-01,\n",
       "         9.21410680e-01,  4.25610185e-01,  8.94582570e-02,\n",
       "        -2.80293489e+00, -1.94358087e+00,  5.53075075e-01,\n",
       "         1.78336918e+00, -4.15879536e+00,  3.81658711e-02,\n",
       "        -9.82370913e-01,  1.28655481e+00,  2.63358259e+00,\n",
       "         2.53867650e+00,  6.74076855e-01, -8.47945642e-03,\n",
       "        -2.04184008e+00, -2.14736924e-01, -2.46774268e+00,\n",
       "        -9.10813361e-02,  1.20651615e+00, -8.35672677e-01,\n",
       "        -2.25172615e+00, -1.57744443e+00,  7.63287783e-01,\n",
       "        -6.86373711e-01, -1.97001219e+00,  1.69232905e+00,\n",
       "         1.60767102e+00, -2.72095728e+00, -5.66020012e-01,\n",
       "        -9.90906060e-01,  2.48729348e+00, -2.95585060e+00,\n",
       "         1.87284160e+00, -1.57076395e+00,  1.90460932e+00,\n",
       "        -5.62886894e-01, -9.79709148e-01, -5.34587622e+00,\n",
       "         3.17114770e-01, -5.42425215e-02,  3.18232203e+00,\n",
       "         9.27754268e-02, -6.25909925e-01, -1.73184752e+00,\n",
       "         5.75854003e-01, -4.47243357e+00,  2.96162868e+00,\n",
       "        -6.52336836e-01, -4.17398548e+00, -4.74440724e-01,\n",
       "         2.51253510e+00, -5.74270606e-01,  5.90882540e-01,\n",
       "        -1.53440714e-01,  3.28218937e-01, -2.01682188e-02,\n",
       "        -1.01400089e+00,  9.09082532e-01, -5.76882839e-01,\n",
       "         9.54458714e-01, -2.12395811e+00, -1.94614220e+00,\n",
       "         1.74527788e+00, -2.12239933e+00, -4.11686945e+00,\n",
       "         2.13731337e+00, -3.88914227e+00, -1.00368671e-01,\n",
       "         5.31783342e-01,  1.70146620e+00, -6.24330081e-02,\n",
       "        -2.31963301e+00,  1.31202149e+00,  3.70094752e+00,\n",
       "         3.87010813e-01, -2.76502341e-01,  2.24563217e+00,\n",
       "        -3.15495491e+00,  9.59492147e-01, -1.84792072e-01,\n",
       "        -1.75569773e+00,  1.02866232e+00,  1.67095885e-01,\n",
       "         1.33929384e+00,  1.08516544e-01,  2.36521602e-01,\n",
       "         8.47409344e+00, -8.76476645e-01, -1.76567733e+00,\n",
       "         9.08241928e-01,  3.59482795e-01, -3.10627055e+00,\n",
       "        -2.27406812e+00, -5.57163537e-01, -1.60335779e+00,\n",
       "         3.22563589e-01, -1.34011781e+00, -2.47360563e+00,\n",
       "         8.45065951e-01, -1.21858788e+00, -1.42931986e+00,\n",
       "        -1.73059249e+00, -4.44030905e+00,  1.06089962e+00,\n",
       "        -1.50694740e+00, -2.85730457e+00, -1.96356559e+00,\n",
       "        -4.70318365e+00, -1.04630005e+00, -2.43409729e+00,\n",
       "        -9.62535024e-01, -6.09806180e-01, -5.91737628e-02,\n",
       "        -3.15850425e+00,  9.90332425e-01,  8.08574021e-01,\n",
       "        -4.68937993e-01,  1.23976243e+00, -3.99985218e+00,\n",
       "        -1.88766682e+00, -1.49936509e+00, -5.58415055e-01,\n",
       "         1.90552831e+00, -2.47196937e+00,  1.05104315e+00,\n",
       "         2.04205513e+00, -1.77497566e+00,  9.44834799e-02,\n",
       "         1.09949648e+00, -2.10026717e+00, -1.27521312e+00,\n",
       "        -1.72796142e+00,  2.32127666e+00, -1.21072304e+00,\n",
       "        -2.04150558e+00, -1.88604021e+00, -2.51538301e+00,\n",
       "        -2.69341540e+00, -2.09534717e+00, -1.18009925e+00,\n",
       "        -1.90306795e+00, -3.20352626e+00, -8.15088749e-01,\n",
       "        -1.56599569e+00,  3.21119976e+00, -1.48699319e+00,\n",
       "        -9.11681473e-01,  2.14969404e-02, -3.10175872e+00,\n",
       "         5.05698967e+00, -1.77642918e+00,  2.38184333e+00,\n",
       "         1.59860671e+00,  6.46987021e-01, -1.82932055e+00,\n",
       "        -1.54952919e+00, -1.02119160e+00, -1.38854945e+00,\n",
       "         1.47696769e+00,  3.11667025e-01, -2.14245653e+00,\n",
       "         2.30826378e+00,  7.31344581e-01, -1.56394279e+00,\n",
       "         1.11303680e-01, -1.11211860e+00, -3.36944795e+00,\n",
       "        -1.63459134e+00, -1.95296764e+00, -4.28073257e-01,\n",
       "        -9.39615548e-01, -8.63037109e-01,  1.03922153e+00,\n",
       "         8.29932392e-01]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorrt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
